{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6: Tree-Based Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this coursework, you will classify houses into **high price** and **low price** categories based on their characteristics using tree-based methods.\n",
    "\n",
    "### **Objectives**\n",
    "- Use the **Ames Housing dataset**, which contains detailed property attributes.\n",
    "- Train and compare **Decision Tree, Random Forest, and XGBoost** classifiers.\n",
    "- Evaluate models using **confusion matrices and ROC-AUC**.\n",
    "- Optimize hyperparameters with **GridSearchCV**.\n",
    "- Interpret model decisions using **SHAP explainability**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# SHAP for explainability\n",
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dataset Description**\n",
    "The dataset used is the **Ames Housing dataset**, which contains detailed information about residential houses in Ames, Iowa. Each row represents a house, and each column describes a characteristic of that house. Let's understand the **15 most important features** in the dataset:\n",
    "\n",
    "1. **OverallQual**: The overall material and finish quality of the house.\n",
    "2. **GrLivArea**: Above ground living area in square feet.\n",
    "3. **GarageCars**: Number of car spaces in the garage.\n",
    "4. **TotalBsmtSF**: Total basement area in square feet.\n",
    "5. **1stFlrSF**: First-floor area in square feet.\n",
    "6. **FullBath**: Number of full bathrooms.\n",
    "7. **TotRmsAbvGrd**: Total number of rooms above ground level (excluding bathrooms).\n",
    "8. **YearBuilt**: Year the house was constructed.\n",
    "9. **Fireplaces**: Number of fireplaces in the house.\n",
    "10. **GarageArea**: Size of the garage in square feet.\n",
    "11. **LotArea**: Total lot size in square feet.\n",
    "12. **KitchenQual**: Kitchen quality rating.\n",
    "13. **BsmtFinSF1**: Finished basement square footage.\n",
    "14. **Neighborhood**: The general location of the property within Ames.\n",
    "15. **MSSubClass**: Identifies the type of dwelling.\n",
    "\n",
    "\n",
    "- **Target Variable:** `SalePrice` (converted into a classification task: High vs. Low price)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Question 1: Data Preprocessing**\n",
    "Before training your models, you need to clean and preprocess the dataset.\n",
    "\n",
    "1. **Load the data `housing.csv` and display the first 5 rows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Ames Housing Dataset\n",
    "\n",
    "\n",
    "# Display the first few rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Convert the `SalePrice` column into a binary classification variable:**\n",
    "   - If the house price is **above the median**, label it as **1 (High price)**.\n",
    "   - If the house price is **below the median**, label it as **0 (Low price)**.\n",
    "   \n",
    "2. **Drop the original `SalePrice` column** after conversion.\n",
    "\n",
    "3. **Encode categorical variables**:\n",
    "   - Some columns contain text (e.g., `Neighborhood`, `House Style`).\n",
    "   - Convert them into numerical values using **Label Encoding**.\n",
    "\n",
    "4. **Standardize numerical features**:\n",
    "   - Scale numerical values to improve model performance.\n",
    "   - Use `StandardScaler()` from `sklearn.preprocessing`.\n",
    "\n",
    "5. **Split the dataset into training and testing sets**:\n",
    "   - Use an **80-20 split** (`train_test_split`).\n",
    "   - Set `random_state=42` for reproducibility.\n",
    "   - Use `stratify=y` to maintain class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert SalePrice into a binary target variable (1 for high price, 0 for low price)\n",
    "\n",
    "\n",
    "# Drop original SalePrice column\n",
    "\n",
    "\n",
    "# Encode categorical variables\n",
    "\n",
    "\n",
    "# Define Features (X) and Target (y)\n",
    "\n",
    "\n",
    "# Convert X to NumPy before train-test split\n",
    "\n",
    "\n",
    "# Perform Train-Test Split (with stratification)\n",
    "\n",
    "\n",
    "# Standardize Numerical Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Question 2: Model Training and Evaluation**\n",
    "You will train three classification models:\n",
    "- **Decision Tree** (`random_state = 42`)\n",
    "- **Random Forest** (`random_state = 42`)\n",
    "\n",
    "1. **Train the models on the training set. Make sure you use the optimal number of trees for the Random Forest.**.\n",
    "2. **Evaluate models using the following metrics**:\n",
    "   - **Confusion Matrix**: Displays True Positives, True Negatives, False Positives, and False Negatives.\n",
    "   - **ROC-AUC Score**: Measures the modelâ€™s ability to distinguish between classes.\n",
    "   - **ROC Curve**: Plots True Positive Rate (TPR) vs. False Positive Rate (FPR).\n",
    "\n",
    "3. **Plot the ROC curves for all models in one figure**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grids\n",
    "\n",
    "\n",
    "# Define base models\n",
    "\n",
    "\n",
    "# Store optimized models\n",
    "\n",
    "\n",
    "# Hyperparameter tuning and model evaluation\n",
    "\n",
    "\n",
    "    # Perform Grid Search to find the best hyperparameters\n",
    "\n",
    "\n",
    "    # Get the best model\n",
    "\n",
    "\n",
    "    # Train with the best hyperparameters\n",
    "\n",
    "\n",
    "    # Predictions\n",
    "\n",
    "\n",
    "    # Evaluation metrics\n",
    "\n",
    "    \n",
    "    # ROC Curve\n",
    "\n",
    "\n",
    "# Plot ROC Curves\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Question 3: Hyperparameter Tuning**\n",
    "Hyperparameter tuning helps improve model performance by finding the best parameters.\n",
    "\n",
    "1. **Tune XGBoost using GridSearchCV with five folds**:\n",
    "   - Search for the best `n_estimators`, `max_depth`, and `learning_rate:`.\n",
    "\n",
    "2. **Show the best number for each hyperparameter**:\n",
    "\n",
    "3. **Calculate a ROC curve and its corresponding AUC. Compare these results with the previous models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid for XGBoost\n",
    "\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "\n",
    "\n",
    "# Perform Grid Search with 5-fold cross-validation\n",
    "\n",
    "\n",
    "# Display the best hyperparameters\n",
    "\n",
    "# Calculate AUC and plot ROC curve.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b265b8b",
   "metadata": {},
   "source": [
    "**Written answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Question 4: Model Explainability with SHAP**\n",
    "Machine learning models can be difficult to interpret. SHAP helps us understand which features are most important in predictions.\n",
    "\n",
    "1. **Apply SHAP to the best-tuned XGBoost model**.\n",
    "2. **Generate a SHAP Summary Plot**:\n",
    "   - Displays the most important features and their impact.\n",
    "3. **Interpret the results**:\n",
    "   - Explain the plot for the top three features?\n",
    "   - Does the result make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best-tuned XGBoost model from GridSearch\n",
    "\n",
    "\n",
    "# Apply SHAP to the best XGBoost model\n",
    "\n",
    "\n",
    "# Generate SHAP Summary Plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Written Answer:**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
