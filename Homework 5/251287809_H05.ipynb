{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LJCGYX0iRh9j",
        "UMaaQ19-Xd1d",
        "Yv9TQIWqoWpY",
        "61faU0aZzRqk",
        "766tNRJzbBFA",
        "mxDVkMQ-hEem",
        "6MKT3NRarkz5",
        "ACAsAnUdLB_o"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emilyberlinghoff/DS3000/blob/main/Homework%205/251287809_H05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 5: Logistic Regression with Variable Selection\n",
        "\n",
        "## Follow These Steps Before Submitting\n",
        "Once you are finished, ensure to complete the following steps.\n",
        "\n",
        "1.  Restart your kernel by clicking **'Runtime' > 'Restart session and run all'**.\n",
        "\n",
        "2.  Fix any errors which result from this.\n",
        "\n",
        "3.  Repeat steps 1. and 2. until your notebook runs without errors.\n",
        "\n",
        "4.  Submit your completed notebook to OWL by the deadline."
      ],
      "metadata": {
        "id": "m9l0b9ZnSgPd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "\n",
        "In this assignment, you will work on a dataset taken from USGS(U.S Geological Survey). This dataset contains earthquake data with a magnitude of 4.5+ and an \"alert\" warning level, recorded between 1976 and 2025. Below is an explanation of the columns included in the dataset:\n",
        "\n",
        "- **`id`**: A unique identifier for the earthquake event.\n",
        "- **`time`**: The timestamp indicating when the earthquake or event occurred, including the date and time in UTC format.\n",
        "- **`latitude`**: The geographical latitude of the earthquake's epicenter, measured in degrees.\n",
        "- **`longitude`**: The geographical longitude of the earthquake's epicenter, measured in degrees.\n",
        "- **`depth`**: The depth at which the earthquake occurred, typically measured in kilometers below the Earth's surface.\n",
        "- **`mag`**: The magnitude of the earthquake, representing the energy released by the seismic event. In this case, a value of 8.6 indicates a very large earthquake.\n",
        "- **`gap`**: The azimuthal gap, which refers to the angular distance between the two most distant seismic stations that recorded the earthquake. A smaller gap typically indicates better global coverage.\n",
        "- **`dmin`**: The minimum distance between the earthquake's epicenter and the nearest seismic station, measured in degrees.\n",
        "- **`rms`**: The root mean square of the amplitude of the seismic waves, representing the strength of the seismic signal.\n",
        "- **`horizontalError`**: The error associated with the latitude and longitude coordinates of the epicenter, typically measured in kilometers.\n",
        "- **`depthError`**: The error associated with the depth measurement of the earthquake, typically measured in kilometers.\n",
        "- **`magError`**: The error associated with the magnitude measurement of the earthquake, representing the uncertainty in the reported magnitude.\n",
        "- **`magNst`**: The number of stations that contributed to the magnitude estimation.\n",
        "- **`Alert` (target)** The alert level issued for the earthquake, whether 'Severe' or 'Non-Severe'.\n",
        "\n",
        "The goal is to train a model for predicting the **`Alert`** which indicates the severity of the earthquake.\n",
        "\n"
      ],
      "metadata": {
        "id": "LJCGYX0iRh9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard imports\n",
        "import numpy as np\n",
        "from itertools import chain, combinations\n",
        "\n",
        "# Data manipulation\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "\n",
        "# Sklearn imports\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "\n",
        "# Plotting packages\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "zoXM0sRHQne_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the data\n",
        "!gdown https://drive.google.com/uc?id=1yL84FMQrfHC_cQsa_V3KTcRAJS0k4DhY"
      ],
      "metadata": {
        "id": "dIBHhqMZUx3R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94d3ef95-3525-459b-a4eb-3d59e188b0ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1yL84FMQrfHC_cQsa_V3KTcRAJS0k4DhY\n",
            "To: /content/earthquakes.parquet\n",
            "\r  0% 0.00/437k [00:00<?, ?B/s]\r100% 437k/437k [00:00<00:00, 13.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Data Preprocessing"
      ],
      "metadata": {
        "id": "l8G0CQ-bXMMM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1.1: Load data\n",
        "\n",
        "(1) Read the **`earthquakes.parquet`** file as a **`polars.DataFrame`** and show its descriptive statistics.\n",
        "\n",
        "(2) Drop column **`id`** and **`time`** and display the first 5 rows of the dataframe.\n",
        "\n",
        "Since **`id`** is unique for each earthquake event that does not contain any predictive information and **`time`** is not directly informative for predicting earthquake severity unless you extract relevant features such as time of day, seasonality, etc."
      ],
      "metadata": {
        "id": "UMaaQ19-Xd1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"earthquakes.parquet\"\n",
        "df = pl.read_parquet(file_path)\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "B6_VKNYOWLnI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "df088f88-78c9-472b-ce8b-1af2c83e8e69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (9, 15)\n",
              "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬──────────┬───────────┬───────────┐\n",
              "│ statistic ┆ id        ┆ time      ┆ latitude  ┆ … ┆ depthErro ┆ magError ┆ magNst    ┆ Alert     │\n",
              "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ r         ┆ ---      ┆ ---       ┆ ---       │\n",
              "│ str       ┆ str       ┆ str       ┆ f64       ┆   ┆ ---       ┆ f64      ┆ f64       ┆ str       │\n",
              "│           ┆           ┆           ┆           ┆   ┆ f64       ┆          ┆           ┆           │\n",
              "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪══════════╪═══════════╪═══════════╡\n",
              "│ count     ┆ 7699      ┆ 7699      ┆ 7699.0    ┆ … ┆ 7490.0    ┆ 5485.0   ┆ 5632.0    ┆ 7699      │\n",
              "│ null_coun ┆ 0         ┆ 0         ┆ 0.0       ┆ … ┆ 209.0     ┆ 2214.0   ┆ 2067.0    ┆ 0         │\n",
              "│ t         ┆           ┆           ┆           ┆   ┆           ┆          ┆           ┆           │\n",
              "│ mean      ┆ null      ┆ null      ┆ 0.999312  ┆ … ┆ 2.571899  ┆ 0.06792  ┆ 46.712713 ┆ null      │\n",
              "│ std       ┆ null      ┆ null      ┆ 32.359887 ┆ … ┆ 3.119655  ┆ 0.057433 ┆ 69.220344 ┆ null      │\n",
              "│ min       ┆ ak012fko1 ┆ 1976-03-2 ┆ -69.7739  ┆ … ┆ 0.0       ┆ 0.0      ┆ 0.0       ┆ Non-Sever │\n",
              "│           ┆ 6th       ┆ 5 00:41:2 ┆           ┆   ┆           ┆          ┆           ┆ e         │\n",
              "│           ┆           ┆ 0.500000+ ┆           ┆   ┆           ┆          ┆           ┆           │\n",
              "│           ┆           ┆ 00:…      ┆           ┆   ┆           ┆          ┆           ┆           │\n",
              "│ 25%       ┆ null      ┆ null      ┆ -21.7389  ┆ … ┆ 1.7       ┆ 0.047    ┆ 18.0      ┆ null      │\n",
              "│ 50%       ┆ null      ┆ null      ┆ -3.5114   ┆ … ┆ 1.8       ┆ 0.059    ┆ 29.0      ┆ null      │\n",
              "│ 75%       ┆ null      ┆ null      ┆ 28.2943   ┆ … ┆ 2.9       ┆ 0.073    ┆ 47.0      ┆ null      │\n",
              "│ max       ┆ uw6156212 ┆ 2024-12-2 ┆ 85.729    ┆ … ┆ 31.95     ┆ 1.642    ┆ 954.0     ┆ Severe    │\n",
              "│           ┆ 6         ┆ 3 06:00:5 ┆           ┆   ┆           ┆          ┆           ┆           │\n",
              "│           ┆           ┆ 9.074000+ ┆           ┆   ┆           ┆          ┆           ┆           │\n",
              "│           ┆           ┆ 00:…      ┆           ┆   ┆           ┆          ┆           ┆           │\n",
              "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴──────────┴───────────┴───────────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (9, 15)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>id</th><th>time</th><th>latitude</th><th>longitude</th><th>depth</th><th>mag</th><th>gap</th><th>dmin</th><th>rms</th><th>horizontalError</th><th>depthError</th><th>magError</th><th>magNst</th><th>Alert</th></tr><tr><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>&quot;7699&quot;</td><td>&quot;7699&quot;</td><td>7699.0</td><td>7699.0</td><td>7699.0</td><td>7699.0</td><td>7375.0</td><td>6997.0</td><td>7673.0</td><td>6481.0</td><td>7490.0</td><td>5485.0</td><td>5632.0</td><td>&quot;7699&quot;</td></tr><tr><td>&quot;null_count&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>324.0</td><td>702.0</td><td>26.0</td><td>1218.0</td><td>209.0</td><td>2214.0</td><td>2067.0</td><td>&quot;0&quot;</td></tr><tr><td>&quot;mean&quot;</td><td>null</td><td>null</td><td>0.999312</td><td>15.173904</td><td>58.990024</td><td>5.657358</td><td>49.060709</td><td>4.109992</td><td>0.822303</td><td>6.974621</td><td>2.571899</td><td>0.06792</td><td>46.712713</td><td>null</td></tr><tr><td>&quot;std&quot;</td><td>null</td><td>null</td><td>32.359887</td><td>128.333755</td><td>119.160114</td><td>0.514095</td><td>39.120351</td><td>5.259451</td><td>0.266227</td><td>2.806992</td><td>3.119655</td><td>0.057433</td><td>69.220344</td><td>null</td></tr><tr><td>&quot;min&quot;</td><td>&quot;ak012fko16th&quot;</td><td>&quot;1976-03-25 00:41:20.500000+00:…</td><td>-69.7739</td><td>-179.9776</td><td>-1.77</td><td>4.5</td><td>7.0</td><td>0.0</td><td>0.04</td><td>0.08</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&quot;Non-Severe&quot;</td></tr><tr><td>&quot;25%&quot;</td><td>null</td><td>null</td><td>-21.7389</td><td>-109.6226</td><td>10.0</td><td>5.4</td><td>25.0</td><td>1.047</td><td>0.66</td><td>5.6</td><td>1.7</td><td>0.047</td><td>18.0</td><td>null</td></tr><tr><td>&quot;50%&quot;</td><td>null</td><td>null</td><td>-3.5114</td><td>42.1877</td><td>13.7</td><td>5.6</td><td>38.0</td><td>2.407</td><td>0.82</td><td>7.1</td><td>1.8</td><td>0.059</td><td>29.0</td><td>null</td></tr><tr><td>&quot;75%&quot;</td><td>null</td><td>null</td><td>28.2943</td><td>141.2441</td><td>42.0</td><td>5.9</td><td>59.0</td><td>4.969</td><td>0.99</td><td>8.6</td><td>2.9</td><td>0.073</td><td>47.0</td><td>null</td></tr><tr><td>&quot;max&quot;</td><td>&quot;uw61562126&quot;</td><td>&quot;2024-12-23 06:00:59.074000+00:…</td><td>85.729</td><td>179.9981</td><td>670.81</td><td>8.6</td><td>321.0</td><td>39.934</td><td>2.1</td><td>88.54</td><td>31.95</td><td>1.642</td><td>954.0</td><td>&quot;Severe&quot;</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop([\"id\", \"time\"])\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "6VQganpcnIEZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "aa37147c-974a-4067-9168-a3592ea181a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (5, 12)\n",
              "┌───────────┬─────────────┬────────┬──────┬───┬────────────┬──────────┬────────┬────────────┐\n",
              "│ latitude  ┆ longitude   ┆ depth  ┆ mag  ┆ … ┆ depthError ┆ magError ┆ magNst ┆ Alert      │\n",
              "│ ---       ┆ ---         ┆ ---    ┆ ---  ┆   ┆ ---        ┆ ---      ┆ ---    ┆ ---        │\n",
              "│ f64       ┆ f64         ┆ f64    ┆ f64  ┆   ┆ f64        ┆ f64      ┆ f64    ┆ str        │\n",
              "╞═══════════╪═════════════╪════════╪══════╪═══╪════════════╪══════════╪════════╪════════════╡\n",
              "│ 35.59     ┆ -90.48      ┆ 15.0   ┆ 4.62 ┆ … ┆ null       ┆ null     ┆ 0.0    ┆ Non-Severe │\n",
              "│ 32.998667 ┆ -115.5575   ┆ 14.19  ┆ 5.8  ┆ … ┆ 1.78       ┆ null     ┆ 0.0    ┆ Severe     │\n",
              "│ 38.19     ┆ -83.95      ┆ 10.0   ┆ 5.0  ┆ … ┆ null       ┆ null     ┆ null   ┆ Non-Severe │\n",
              "│ 35.816    ┆ -117.816333 ┆ 4.766  ┆ 4.7  ┆ … ┆ 31.61      ┆ 0.424    ┆ 9.0    ┆ Non-Severe │\n",
              "│ 33.0955   ┆ -115.6245   ┆ 18.904 ┆ 5.75 ┆ … ┆ 0.67       ┆ 0.161    ┆ 6.0    ┆ Non-Severe │\n",
              "└───────────┴─────────────┴────────┴──────┴───┴────────────┴──────────┴────────┴────────────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (5, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>latitude</th><th>longitude</th><th>depth</th><th>mag</th><th>gap</th><th>dmin</th><th>rms</th><th>horizontalError</th><th>depthError</th><th>magError</th><th>magNst</th><th>Alert</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>35.59</td><td>-90.48</td><td>15.0</td><td>4.62</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>&quot;Non-Severe&quot;</td></tr><tr><td>32.998667</td><td>-115.5575</td><td>14.19</td><td>5.8</td><td>79.0</td><td>0.05768</td><td>0.17</td><td>1.03</td><td>1.78</td><td>null</td><td>0.0</td><td>&quot;Severe&quot;</td></tr><tr><td>38.19</td><td>-83.95</td><td>10.0</td><td>5.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;Non-Severe&quot;</td></tr><tr><td>35.816</td><td>-117.816333</td><td>4.766</td><td>4.7</td><td>135.0</td><td>null</td><td>0.66</td><td>2.51</td><td>31.61</td><td>0.424</td><td>9.0</td><td>&quot;Non-Severe&quot;</td></tr><tr><td>33.0955</td><td>-115.6245</td><td>18.904</td><td>5.75</td><td>34.0</td><td>null</td><td>0.34</td><td>0.56</td><td>0.67</td><td>0.161</td><td>6.0</td><td>&quot;Non-Severe&quot;</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1.2: Handle null values\n",
        "\n",
        "The result of the `null_count` function indicates that some columns contain null values. Fill these null values with the median of the corresponding column and display the first 5 rows of the resulting dataframe."
      ],
      "metadata": {
        "id": "Yv9TQIWqoWpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.null_count() # uncomment and run this code"
      ],
      "metadata": {
        "id": "5SkBkhO7ouYE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "a6f97c08-28c1-4737-fb7d-1c6dcf8b0e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (1, 12)\n",
              "┌──────────┬───────────┬───────┬─────┬───┬────────────┬──────────┬────────┬───────┐\n",
              "│ latitude ┆ longitude ┆ depth ┆ mag ┆ … ┆ depthError ┆ magError ┆ magNst ┆ Alert │\n",
              "│ ---      ┆ ---       ┆ ---   ┆ --- ┆   ┆ ---        ┆ ---      ┆ ---    ┆ ---   │\n",
              "│ u32      ┆ u32       ┆ u32   ┆ u32 ┆   ┆ u32        ┆ u32      ┆ u32    ┆ u32   │\n",
              "╞══════════╪═══════════╪═══════╪═════╪═══╪════════════╪══════════╪════════╪═══════╡\n",
              "│ 0        ┆ 0         ┆ 0     ┆ 0   ┆ … ┆ 209        ┆ 2214     ┆ 2067   ┆ 0     │\n",
              "└──────────┴───────────┴───────┴─────┴───┴────────────┴──────────┴────────┴───────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (1, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>latitude</th><th>longitude</th><th>depth</th><th>mag</th><th>gap</th><th>dmin</th><th>rms</th><th>horizontalError</th><th>depthError</th><th>magError</th><th>magNst</th><th>Alert</th></tr><tr><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>0</td><td>324</td><td>702</td><td>26</td><td>1218</td><td>209</td><td>2214</td><td>2067</td><td>0</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filled_columns = []\n",
        "for col in df.columns:\n",
        "    median_value = df[col].median()\n",
        "    if median_value is not None:  # Ensure median value is valid\n",
        "        filled_columns.append(df[col].fill_null(median_value).alias(col))\n",
        "    else:\n",
        "        filled_columns.append(df[col])  # Keep column unchanged if median is None\n",
        "\n",
        "df = df.with_columns(filled_columns)\n",
        "print(df.head(5))"
      ],
      "metadata": {
        "id": "YvX9BKCnovfk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be96764b-084c-4844-81aa-242a0ecf4add"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (5, 12)\n",
            "┌───────────┬─────────────┬────────┬──────┬───┬────────────┬──────────┬────────┬────────────┐\n",
            "│ latitude  ┆ longitude   ┆ depth  ┆ mag  ┆ … ┆ depthError ┆ magError ┆ magNst ┆ Alert      │\n",
            "│ ---       ┆ ---         ┆ ---    ┆ ---  ┆   ┆ ---        ┆ ---      ┆ ---    ┆ ---        │\n",
            "│ f64       ┆ f64         ┆ f64    ┆ f64  ┆   ┆ f64        ┆ f64      ┆ f64    ┆ str        │\n",
            "╞═══════════╪═════════════╪════════╪══════╪═══╪════════════╪══════════╪════════╪════════════╡\n",
            "│ 35.59     ┆ -90.48      ┆ 15.0   ┆ 4.62 ┆ … ┆ 1.8        ┆ 0.059    ┆ 0.0    ┆ Non-Severe │\n",
            "│ 32.998667 ┆ -115.5575   ┆ 14.19  ┆ 5.8  ┆ … ┆ 1.78       ┆ 0.059    ┆ 0.0    ┆ Severe     │\n",
            "│ 38.19     ┆ -83.95      ┆ 10.0   ┆ 5.0  ┆ … ┆ 1.8        ┆ 0.059    ┆ 29.0   ┆ Non-Severe │\n",
            "│ 35.816    ┆ -117.816333 ┆ 4.766  ┆ 4.7  ┆ … ┆ 31.61      ┆ 0.424    ┆ 9.0    ┆ Non-Severe │\n",
            "│ 33.0955   ┆ -115.6245   ┆ 18.904 ┆ 5.75 ┆ … ┆ 0.67       ┆ 0.161    ┆ 6.0    ┆ Non-Severe │\n",
            "└───────────┴─────────────┴────────┴──────┴───┴────────────┴──────────┴────────┴────────────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1.3: Explore target distribution\n",
        "\n",
        "Count the number of instances of each severity level of the earthquake in the dataset.\n",
        "\n",
        "Comment on your findings, providing insights into the distribution of different severity levels."
      ],
      "metadata": {
        "id": "61faU0aZzRqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "severity_counts = df[\"Alert\"].value_counts()\n",
        "print(severity_counts)"
      ],
      "metadata": {
        "id": "8T3pp1W0zRDt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da0619a6-2a3e-42ed-e519-73896e261c71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (2, 2)\n",
            "┌────────────┬───────┐\n",
            "│ Alert      ┆ count │\n",
            "│ ---        ┆ ---   │\n",
            "│ str        ┆ u32   │\n",
            "╞════════════╪═══════╡\n",
            "│ Severe     ┆ 331   │\n",
            "│ Non-Severe ┆ 7368  │\n",
            "└────────────┴───────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset reveals a significant imbalance in the distribution of earthquake severity levels, with 7,368 instances of Non-Severe earthquakes compared to only 331 occurrences of Severe earthquakes. This suggests that severe earthquakes are relatively rare, comprising only a small fraction of recorded seismic events. The overwhelming prevalence of non-severe earthquakes indicates that most seismic activities in the dataset are of lower intensity."
      ],
      "metadata": {
        "id": "ZtiF3a-qzpPy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1.4: Convert target variable\n",
        "\n",
        "Convert **`Alert`** to a binary numerical target:\n",
        "- Replace **`Severe`** with 1.\n",
        "- Replace **`Non-Severe`** with 0.\n",
        "\n",
        "Display the first 5 rows of the resulting dataframe.\n",
        "\n",
        "Hint: If you use the `replace` method, the resulting column will still be of string type. Use `cast` to make it `Float64` after replacement."
      ],
      "metadata": {
        "id": "766tNRJzbBFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.with_columns(\n",
        "    df[\"Alert\"]\n",
        "    .replace({\"Severe\": 1, \"Non-Severe\": 0})  # Replace values\n",
        "    .cast(pl.Float64)  # Cast to Float64\n",
        "    .alias(\"Alert\")  # Ensure column name remains the same\n",
        ")\n",
        "print(df.head(5))"
      ],
      "metadata": {
        "id": "qjO3iAxvaTpT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30cdbe70-412e-4bfd-800d-13c7f6f5d32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (5, 12)\n",
            "┌───────────┬─────────────┬────────┬──────┬───┬────────────┬──────────┬────────┬───────┐\n",
            "│ latitude  ┆ longitude   ┆ depth  ┆ mag  ┆ … ┆ depthError ┆ magError ┆ magNst ┆ Alert │\n",
            "│ ---       ┆ ---         ┆ ---    ┆ ---  ┆   ┆ ---        ┆ ---      ┆ ---    ┆ ---   │\n",
            "│ f64       ┆ f64         ┆ f64    ┆ f64  ┆   ┆ f64        ┆ f64      ┆ f64    ┆ f64   │\n",
            "╞═══════════╪═════════════╪════════╪══════╪═══╪════════════╪══════════╪════════╪═══════╡\n",
            "│ 35.59     ┆ -90.48      ┆ 15.0   ┆ 4.62 ┆ … ┆ 1.8        ┆ 0.059    ┆ 0.0    ┆ 0.0   │\n",
            "│ 32.998667 ┆ -115.5575   ┆ 14.19  ┆ 5.8  ┆ … ┆ 1.78       ┆ 0.059    ┆ 0.0    ┆ 1.0   │\n",
            "│ 38.19     ┆ -83.95      ┆ 10.0   ┆ 5.0  ┆ … ┆ 1.8        ┆ 0.059    ┆ 29.0   ┆ 0.0   │\n",
            "│ 35.816    ┆ -117.816333 ┆ 4.766  ┆ 4.7  ┆ … ┆ 31.61      ┆ 0.424    ┆ 9.0    ┆ 0.0   │\n",
            "│ 33.0955   ┆ -115.6245   ┆ 18.904 ┆ 5.75 ┆ … ┆ 0.67       ┆ 0.161    ┆ 6.0    ┆ 0.0   │\n",
            "└───────────┴─────────────┴────────┴──────┴───┴────────────┴──────────┴────────┴───────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1.5: Train test split\n",
        "\n",
        "Split the dataset into training and testing sets:\n",
        "- With **30% testing data** and **70% training data**.\n",
        "- Set the **random state** to **2025**.\n",
        "- Use **stratified splitting** to **maintain the same proportion of each class** in the target variable (**`Alert`**) in both the training and testing sets.\n",
        "\n",
        "Display the descriptive statistics for X_train and X_test."
      ],
      "metadata": {
        "id": "mxDVkMQ-hEem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Polars DataFrame to Pandas for scikit-learn compatibility\n",
        "df_pandas = df.to_pandas()\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df_pandas.drop(columns=[\"Alert\"])\n",
        "y = df_pandas[\"Alert\"]\n",
        "\n",
        "# Perform stratified train-test split (70% training, 30% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=2025, stratify=y\n",
        ")\n",
        "\n",
        "# Convert back to Polars DataFrame for analysis\n",
        "X_train_pl = pl.from_pandas(X_train)\n",
        "X_test_pl = pl.from_pandas(X_test)\n",
        "\n",
        "# Display descriptive statistics\n",
        "print(\"Descriptive Statistics for X_train:\")\n",
        "print(X_train_pl.describe())\n",
        "\n",
        "print(\"\\nDescriptive Statistics for X_test:\")\n",
        "print(X_test_pl.describe())"
      ],
      "metadata": {
        "id": "DG9n0DVHwJp0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c54d8c5c-6b28-4d33-ba2c-2fd55b05a086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descriptive Statistics for X_train:\n",
            "shape: (9, 12)\n",
            "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬──────────┬───────────┐\n",
            "│ statistic ┆ latitude  ┆ longitude ┆ depth     ┆ … ┆ horizonta ┆ depthErro ┆ magError ┆ magNst    │\n",
            "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ lError    ┆ r         ┆ ---      ┆ ---       │\n",
            "│ str       ┆ f64       ┆ f64       ┆ f64       ┆   ┆ ---       ┆ ---       ┆ f64      ┆ f64       │\n",
            "│           ┆           ┆           ┆           ┆   ┆ f64       ┆ f64       ┆          ┆           │\n",
            "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪══════════╪═══════════╡\n",
            "│ count     ┆ 5389.0    ┆ 5389.0    ┆ 5389.0    ┆ … ┆ 5389.0    ┆ 5389.0    ┆ 5389.0   ┆ 5389.0    │\n",
            "│ null_coun ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0      ┆ 0.0       │\n",
            "│ t         ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆           │\n",
            "│ mean      ┆ 1.196909  ┆ 14.828723 ┆ 58.076958 ┆ … ┆ 6.98469   ┆ 2.524978  ┆ 0.065569 ┆ 41.092225 │\n",
            "│ std       ┆ 32.640056 ┆ 128.02419 ┆ 118.04858 ┆ … ┆ 2.648101  ┆ 3.065915  ┆ 0.049294 ┆ 57.690582 │\n",
            "│           ┆           ┆ 9         ┆ 9         ┆   ┆           ┆           ┆          ┆           │\n",
            "│ min       ┆ -69.7739  ┆ -179.9776 ┆ -1.77     ┆ … ┆ 0.08      ┆ 0.0       ┆ 0.0      ┆ 0.0       │\n",
            "│ 25%       ┆ -21.7957  ┆ -110.7745 ┆ 10.0      ┆ … ┆ 5.9       ┆ 1.7       ┆ 0.052    ┆ 21.0      │\n",
            "│ 50%       ┆ -3.3488   ┆ 39.3035   ┆ 13.0      ┆ … ┆ 7.1       ┆ 1.8       ┆ 0.059    ┆ 29.0      │\n",
            "│ 75%       ┆ 29.3592   ┆ 140.6546  ┆ 41.14     ┆ … ┆ 8.21      ┆ 2.8       ┆ 0.068    ┆ 39.0      │\n",
            "│ max       ┆ 85.729    ┆ 179.9604  ┆ 670.81    ┆ … ┆ 88.54     ┆ 31.95     ┆ 1.642    ┆ 884.0     │\n",
            "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴──────────┴───────────┘\n",
            "\n",
            "Descriptive Statistics for X_test:\n",
            "shape: (9, 12)\n",
            "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬──────────┬───────────┐\n",
            "│ statistic ┆ latitude  ┆ longitude ┆ depth     ┆ … ┆ horizonta ┆ depthErro ┆ magError ┆ magNst    │\n",
            "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ lError    ┆ r         ┆ ---      ┆ ---       │\n",
            "│ str       ┆ f64       ┆ f64       ┆ f64       ┆   ┆ ---       ┆ ---       ┆ f64      ┆ f64       │\n",
            "│           ┆           ┆           ┆           ┆   ┆ f64       ┆ f64       ┆          ┆           │\n",
            "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪══════════╪═══════════╡\n",
            "│ count     ┆ 2310.0    ┆ 2310.0    ┆ 2310.0    ┆ … ┆ 2310.0    ┆ 2310.0    ┆ 2310.0   ┆ 2310.0    │\n",
            "│ null_coun ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0      ┆ 0.0       │\n",
            "│ t         ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆           │\n",
            "│ mean      ┆ 0.53834   ┆ 15.979179 ┆ 61.120117 ┆ … ┆ 7.017238  ┆ 2.611522  ┆ 0.064856 ┆ 43.975325 │\n",
            "│ std       ┆ 31.698853 ┆ 129.07724 ┆ 121.71298 ┆ … ┆ 2.39899   ┆ 3.11102   ┆ 0.047096 ┆ 64.174417 │\n",
            "│           ┆           ┆ 9         ┆ 2         ┆   ┆           ┆           ┆          ┆           │\n",
            "│ min       ┆ -65.552   ┆ -179.9533 ┆ -0.924    ┆ … ┆ 0.08      ┆ 0.0       ┆ 0.0      ┆ 0.0       │\n",
            "│ 25%       ┆ -21.6779  ┆ -108.662  ┆ 10.0      ┆ … ┆ 5.9       ┆ 1.7       ┆ 0.052    ┆ 22.0      │\n",
            "│ 50%       ┆ -3.8727   ┆ 45.0259   ┆ 15.44     ┆ … ┆ 7.1       ┆ 1.8       ┆ 0.059    ┆ 29.0      │\n",
            "│ 75%       ┆ 26.404    ┆ 141.6605  ┆ 43.0      ┆ … ┆ 8.3       ┆ 3.0       ┆ 0.066    ┆ 40.0      │\n",
            "│ max       ┆ 85.2392   ┆ 179.9981  ┆ 639.503   ┆ … ┆ 15.3      ┆ 31.61     ┆ 1.334    ┆ 954.0     │\n",
            "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴──────────┴───────────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Sequential Feature Selection"
      ],
      "metadata": {
        "id": "DkcOJ8fErgu8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2.1: Forward Selection\n",
        "\n",
        "Create a pipeline using [`SequentialFeatureSelector`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html) to perform **forward** feature selection:\n",
        "- Standardize the data, ensuring each feature has a mean of 0 and a standard deviation of 1.\n",
        "- Use **ROC AUC** as the scoring metric for feature selection. Conduct **5-fold cross-validation** to evaluate the model. Set the **tolerance for stopping** the selection process to **0.001**.\n",
        "- Configure the logistic regression to use the default **`lbfgs`** as solver with **no penalty**. Set the **maximum number of iterations** to **1000**. Use a **balanced** weight that adjust weights inversely proportional to class frequencies in the input data. Set the **random state** to **2025**.\n",
        "\n",
        "Fit the pipeline and report the subset of variables on this method.\n"
      ],
      "metadata": {
        "id": "6MKT3NRarkz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Standardization step\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Define Logistic Regression Model\n",
        "log_reg = LogisticRegression(\n",
        "    solver=\"lbfgs\",\n",
        "    penalty=None,  # No regularization\n",
        "    max_iter=1000,\n",
        "    class_weight=\"balanced\",  # Adjusts for class imbalance\n",
        "    random_state=2025\n",
        ")\n",
        "\n",
        "# Define Forward Feature Selection using standard cross-validation (not StratifiedKFold)\n",
        "sfs = SequentialFeatureSelector(\n",
        "    log_reg,\n",
        "    n_features_to_select=\"auto\",  # Auto-determines the best number of features\n",
        "    direction=\"forward\",  # Forward selection\n",
        "    scoring=\"roc_auc\",  # Use ROC AUC as metric\n",
        "    cv=5,  # 5-fold cross-validation\n",
        "    tol=0.001,  # Stopping tolerance\n",
        "    n_jobs=-1  # Use all available processors\n",
        ")\n",
        "\n",
        "# Create a pipeline with standardization and feature selection\n",
        "pipeline = Pipeline([\n",
        "    (\"scaler\", scaler),\n",
        "    (\"feature_selection\", sfs),\n",
        "    (\"log_reg\", log_reg)\n",
        "])\n",
        "\n",
        "# Fit the pipeline\n",
        "pipeline.fit(X, y)\n",
        "\n",
        "# Get the selected features\n",
        "selected_features = X.columns[pipeline.named_steps[\"feature_selection\"].get_support()]\n",
        "\n",
        "# Output the selected features\n",
        "print(\"Selected Features:\", selected_features.tolist())"
      ],
      "metadata": {
        "id": "I0gfWRgo1P14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e34dcb8-7dd7-4ebf-d254-7ed4464baf59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features: ['latitude', 'depth', 'mag', 'dmin', 'horizontalError']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2.2: Backward Selection\n",
        "\n",
        "Create a pipeline using [`SequentialFeatureSelector`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html) to perform **backward** feature selection. Keep all other configurations the same as in the previous question\n",
        "\n",
        "Fit the pipeline and report the subset of variables on this method.\n"
      ],
      "metadata": {
        "id": "ACAsAnUdLB_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Backward Feature Selection using the same settings as before\n",
        "sbs = SequentialFeatureSelector(\n",
        "    log_reg,\n",
        "    n_features_to_select=\"auto\",  # Auto-determines the best number of features\n",
        "    direction=\"backward\",  # Backward selection\n",
        "    scoring=\"roc_auc\",  # Use ROC AUC as metric\n",
        "    cv=5,  # 5-fold cross-validation\n",
        "    tol=0.001,  # Stopping tolerance\n",
        "    n_jobs=-1  # Use all available processors\n",
        ")\n",
        "\n",
        "# Create a pipeline with standardization and feature selection\n",
        "pipeline = Pipeline([\n",
        "    (\"scaler\", scaler),\n",
        "    (\"feature_selection\", sbs),\n",
        "    (\"log_reg\", log_reg)\n",
        "])\n",
        "\n",
        "# Fit the pipeline\n",
        "pipeline.fit(X, y)\n",
        "\n",
        "# Get the selected features\n",
        "selected_features = X.columns[pipeline.named_steps[\"feature_selection\"].get_support()]\n",
        "\n",
        "# Output the selected features\n",
        "print(\"Selected Features:\", selected_features.tolist())"
      ],
      "metadata": {
        "id": "fnrafwMxK08Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc2de24c-1f29-4728-d9d7-f38280782ba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features: ['latitude', 'depth', 'mag', 'gap', 'dmin', 'rms', 'horizontalError', 'depthError', 'magError', 'magNst']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2.3: Compare results & find the best model\n",
        "\n",
        "Compare and discuss the selected subset of variables obtained from both methods used in the previous steps.\n",
        "\n",
        "Perform an **exhaustive search** over all possible subsets of the remaining variables using **5-fold cross-validation** to find the best model. Use the same Logistic Regression configurations as in previous questions.\n",
        "\n",
        "Hint: If you have correctly followed the previous steps, you should have **five remaining variables** to evaluate in the exhaustive search."
      ],
      "metadata": {
        "id": "8cSXKQpXMlwm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Your written answer here)\n",
        "\n",
        "Among all 11 variables, forward selection resulted in 5 features, while backward selection selected 10 features. This indicates that backward selection retains more variables, perhaps due to its nature of removing less impactful features instead of building up the model iteratively. Both selection results agree on keeping `['latitude', 'depth', 'mag', 'dmin', 'horizontalError']`. We should then conduct an exhaustive search using the remaining five variables `['longitude', 'gap', 'depthError', 'magError', 'magNst']`."
      ],
      "metadata": {
        "id": "fEAnA4JUOgw_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qjjk41LbMlo5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "4f479fac-03d0-4fba-f318-0bf350358feb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "No such file or directory (os error 2): /mnt/data/earthquakes.parquet",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-1c7e53619280>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Load the dataset using Polars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/mnt/data/earthquakes.parquet\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Drop 'id' and 'time' columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/polars/_utils/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mold_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             )\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__signature__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/polars/_utils/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mold_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             )\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__signature__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/polars/io/parquet/functions.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(source, columns, n_rows, row_index_name, row_index_offset, parallel, use_statistics, hive_partitioning, glob, schema, hive_schema, try_parse_hive_dates, rechunk, low_memory, storage_options, retries, use_pyarrow, pyarrow_options, memory_map, include_file_paths, allow_missing_columns)\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mlf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/polars/lazyframe/frame.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, streaming, engine, background, _eager, **_kwargs)\u001b[0m\n\u001b[1;32m   2048\u001b[0m         \u001b[0;31m# Only for testing purposes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m         \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post_opt_callback\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrap_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mldf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory (os error 2): /mnt/data/earthquakes.parquet"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2.4: Fit the best model\n",
        "\n",
        "Train a logistic regression model with the best variables selected.\n",
        "\n",
        "Display the model's coefficients and intercept."
      ],
      "metadata": {
        "id": "Qe7q3KFzSCOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "YdCYh9e3MlPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2.5: Measure model's performance\n",
        "\n",
        "Construct a **95% confidence interval** for both accuracy and AUC using **100 bootstrap resamples** of the test set."
      ],
      "metadata": {
        "id": "NkqKda5RV0hZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(2025) # DO NOT DELETE\n",
        "\n",
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "u7JoX1dnMFUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Regularization"
      ],
      "metadata": {
        "id": "DMFb9isT5HG7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3.1: Ridge penalization\n",
        "\n",
        "Create a pipeline using [`LogisticRegressionCV`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html) to implement a logistic regression with **Ridge penalization**:\n",
        "- Standardize the data, ensuring each feature has a mean of 0 and a standard deviation of 1.\n",
        "- Configure the **`LogisticRegressionCV`** to use **`saga`** as solver. Use the default **`Cs = 10`**. Set the **maximum number of iterations** to **1000**. Use a **balanced** weight that adjust weights inversely proportional to class frequencies in the input data. Set the **random state** to **2025**. Use **5-fold cross-validation**.\n",
        "\n",
        "Fit the pipeline to get the best model.\n",
        "\n",
        "Construct a **95% confidence interval** for both accuracy and AUC using **100 bootstrap resamples** of the test set."
      ],
      "metadata": {
        "id": "UN8KyRvX6D_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(2025) # DO NOT DELETE\n",
        "\n",
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "QZh1TMq942kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3.2: Lasso penalization\n",
        "\n",
        "Create a pipeline using [`LogisticRegressionCV`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html) to implement a logistic regression with **Lasso penalization**:\n",
        "- Standardize the data, ensuring each feature has a mean of 0 and a standard deviation of 1.\n",
        "- Configure the **`LogisticRegressionCV`** to use **`saga`** as solver. Use the default **`Cs = 10`**. Set the **maximum number of iterations** to **1000**. Use a **balanced** weight that adjust weights inversely proportional to class frequencies in the input data. Set the **random state** to **2025**. Use **5-fold cross-validation**.\n",
        "\n",
        "Fit the pipeline to get the best model.\n",
        "\n",
        "Construct a **95% confidence interval** for both accuracy and AUC using **100 bootstrap resamples** of the test set."
      ],
      "metadata": {
        "id": "LWwwyAFxEs3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(2025) # DO NOT DELETE\n",
        "\n",
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "EOFq1EqUDR5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3.3: Ridge vs Lasso\n",
        "\n",
        "Report the coefficients from the best-performing models with Ridge and Lasso penalties.\n",
        "\n",
        "Compare and discuss how the coefficient magnitudes differ between Ridge and Lasso, and explain."
      ],
      "metadata": {
        "id": "yB9OrR_SFmUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "90aHPsKTE6vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Your written answer here)\n"
      ],
      "metadata": {
        "id": "3fgLpuw3ItWi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 4: Overall Comparison\n",
        "\n",
        "Compare the best models obtained using **Sequential Feature Selection**, **Ridge Regularization**, and **Lasso Regularization** by plotting the ROC curve for each model on a single plot. Additionally, include a diagonal reference line representing random classification performance (i.e., an ROC curve with an AUC of 0.5).\n",
        "\n",
        "Provide a brief analysis and comment on your findings (no need to identify the best model)."
      ],
      "metadata": {
        "id": "DoMw6CaUMx-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "VI4pxr-mHj8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Your written answer here)\n"
      ],
      "metadata": {
        "id": "rxg6xDcWPzyc"
      }
    }
  ]
}